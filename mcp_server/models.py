# generated by fastapi-codegen:
#   filename:  openapi.yaml
#   timestamp: 2025-06-29T01:01:47+00:00

from __future__ import annotations

from enum import Enum
from typing import Any, Dict, List, Optional

from pydantic import BaseModel, Field, RootModel


class CheckValidCredsRequest(BaseModel):
    pass


class CheckValidCredsResponse(BaseModel):
    hasValidCreds: Optional[bool] = Field(
        None, description='If set to `true`, the credentials exist and are valid.'
    )


class AuthorizationType(Enum):
    AUTHORIZATION_TYPE_UNSPECIFIED = 'AUTHORIZATION_TYPE_UNSPECIFIED'
    AUTHORIZATION_CODE = 'AUTHORIZATION_CODE'
    GOOGLE_PLUS_AUTHORIZATION_CODE = 'GOOGLE_PLUS_AUTHORIZATION_CODE'
    FIRST_PARTY_OAUTH = 'FIRST_PARTY_OAUTH'


class DataRefreshType(Enum):
    DATA_REFRESH_TYPE_UNSPECIFIED = 'DATA_REFRESH_TYPE_UNSPECIFIED'
    SLIDING_WINDOW = 'SLIDING_WINDOW'
    CUSTOM_SLIDING_WINDOW = 'CUSTOM_SLIDING_WINDOW'


class TransferType(Enum):
    TRANSFER_TYPE_UNSPECIFIED = 'TRANSFER_TYPE_UNSPECIFIED'
    BATCH = 'BATCH'
    STREAMING = 'STREAMING'


class Type(Enum):
    TYPE_UNSPECIFIED = 'TYPE_UNSPECIFIED'
    STRING = 'STRING'
    INTEGER = 'INTEGER'
    DOUBLE = 'DOUBLE'
    BOOLEAN = 'BOOLEAN'
    RECORD = 'RECORD'
    PLUS_PAGE = 'PLUS_PAGE'


class DataSourceParameter(BaseModel):
    allowedValues: Optional[List[str]] = Field(
        None, description='All possible values for the parameter.'
    )
    deprecated: Optional[bool] = Field(
        None,
        description='If true, it should not be used in new transfers, and it should not be visible to users.',
    )
    description: Optional[str] = Field(None, description='Parameter description.')
    displayName: Optional[str] = Field(
        None, description='Parameter display name in the user interface.'
    )
    fields: Optional[List[DataSourceParameter]] = Field(
        None, description='Deprecated. This field has no effect.'
    )
    immutable: Optional[bool] = Field(
        None, description='Cannot be changed after initial creation.'
    )
    maxValue: Optional[float] = Field(
        None,
        description='For integer and double values specifies maximum allowed value.',
    )
    minValue: Optional[float] = Field(
        None,
        description='For integer and double values specifies minimum allowed value.',
    )
    paramId: Optional[str] = Field(None, description='Parameter identifier.')
    recurse: Optional[bool] = Field(
        None, description='Deprecated. This field has no effect.'
    )
    repeated: Optional[bool] = Field(
        None, description='Deprecated. This field has no effect.'
    )
    required: Optional[bool] = Field(None, description='Is parameter required.')
    type: Optional[Type] = Field(None, description='Parameter type.')
    validationDescription: Optional[str] = Field(
        None,
        description='Description of the requirements for this field, in case the user input does not fulfill the regex pattern or min/max values.',
    )
    validationHelpUrl: Optional[str] = Field(
        None,
        description='URL to a help document to further explain the naming requirements.',
    )
    validationRegex: Optional[str] = Field(
        None,
        description='Regular expression which can be used for parameter validation.',
    )


class EmailPreferences(BaseModel):
    enableFailureEmail: Optional[bool] = Field(
        None,
        description='If true, email notifications will be sent on transfer run failures.',
    )


class Empty(BaseModel):
    pass


class EnrollDataSourcesRequest(BaseModel):
    dataSourceIds: Optional[List[str]] = Field(
        None,
        description='Data sources that are enrolled. It is required to provide at least one data source id.',
    )


class Location(BaseModel):
    displayName: Optional[str] = Field(
        None,
        description='The friendly name for this location, typically a nearby city name. For example, "Tokyo".',
    )
    labels: Optional[Dict[str, str]] = Field(
        None,
        description='Cross-service attributes for the location. For example {"cloud.googleapis.com/region": "us-east1"}',
    )
    locationId: Optional[str] = Field(
        None,
        description='The canonical id for this location. For example: `"us-east1"`.',
    )
    metadata: Optional[Dict[str, Any]] = Field(
        None,
        description='Service-specific metadata. For example the available capacity at the given location.',
    )
    name: Optional[str] = Field(
        None,
        description='Resource name for the location, which may vary between implementations. For example: `"projects/example-project/locations/us-east1"`',
    )


class ScheduleOptions(BaseModel):
    disableAutoScheduling: Optional[bool] = Field(
        None,
        description='If true, automatic scheduling of data transfer runs for this configuration will be disabled. The runs can be started on ad-hoc basis using StartManualTransferRuns API. When automatic scheduling is disabled, the TransferConfig.schedule field will be ignored.',
    )
    endTime: Optional[str] = Field(
        None,
        description='Defines time to stop scheduling transfer runs. A transfer run cannot be scheduled at or after the end time. The end time can be changed at any moment. The time when a data transfer can be trigerred manually is not limited by this option.',
    )
    startTime: Optional[str] = Field(
        None,
        description='Specifies time to start scheduling transfer runs. The first run will be scheduled at or after the start time according to a recurrence pattern defined in the schedule string. The start time can be changed at any moment. The time when a data transfer can be trigerred manually is not limited by this option.',
    )


class ScheduleTransferRunsRequest(BaseModel):
    endTime: Optional[str] = Field(
        None,
        description='Required. End time of the range of transfer runs. For example, `"2017-05-30T00:00:00+00:00"`.',
    )
    startTime: Optional[str] = Field(
        None,
        description='Required. Start time of the range of transfer runs. For example, `"2017-05-25T00:00:00+00:00"`.',
    )


class Status(BaseModel):
    code: Optional[int] = Field(
        None,
        description='The status code, which should be an enum value of google.rpc.Code.',
    )
    details: Optional[List[Dict[str, Any]]] = Field(
        None,
        description='A list of messages that carry the error details. There is a common set of message types for APIs to use.',
    )
    message: Optional[str] = Field(
        None,
        description='A developer-facing error message, which should be in English. Any user-facing error message should be localized and sent in the google.rpc.Status.details field, or localized by the client.',
    )


class TimeRange(BaseModel):
    endTime: Optional[str] = Field(
        None,
        description='End time of the range of transfer runs. For example, `"2017-05-30T00:00:00+00:00"`. The end_time must not be in the future. Creates transfer runs where run_time is in the range between start_time (inclusive) and end_time (exclusive).',
    )
    startTime: Optional[str] = Field(
        None,
        description='Start time of the range of transfer runs. For example, `"2017-05-25T00:00:00+00:00"`. The start_time must be strictly less than the end_time. Creates transfer runs where run_time is in the range between start_time (inclusive) and end_time (exclusive).',
    )


class State(Enum):
    TRANSFER_STATE_UNSPECIFIED = 'TRANSFER_STATE_UNSPECIFIED'
    PENDING = 'PENDING'
    RUNNING = 'RUNNING'
    SUCCEEDED = 'SUCCEEDED'
    FAILED = 'FAILED'
    CANCELLED = 'CANCELLED'


class Severity(Enum):
    MESSAGE_SEVERITY_UNSPECIFIED = 'MESSAGE_SEVERITY_UNSPECIFIED'
    INFO = 'INFO'
    WARNING = 'WARNING'
    ERROR = 'ERROR'


class TransferMessage(BaseModel):
    messageText: Optional[str] = Field(None, description='Message text.')
    messageTime: Optional[str] = Field(
        None, description='Time when message was logged.'
    )
    severity: Optional[Severity] = Field(None, description='Message severity.')


class TransferRun(BaseModel):
    dataSourceId: Optional[str] = Field(
        None, description='Output only. Data source id.'
    )
    destinationDatasetId: Optional[str] = Field(
        None, description='Output only. The BigQuery target dataset id.'
    )
    emailPreferences: Optional[EmailPreferences] = Field(
        None,
        description='Output only. Email notifications will be sent according to these preferences to the email address of the user who owns the transfer config this run was derived from.',
    )
    endTime: Optional[str] = Field(
        None,
        description='Output only. Time when transfer run ended. Parameter ignored by server for input requests.',
    )
    errorStatus: Optional[Status] = Field(
        None, description='Status of the transfer run.'
    )
    name: Optional[str] = Field(
        None,
        description='The resource name of the transfer run. Transfer run names have the form `projects/{project_id}/locations/{location}/transferConfigs/{config_id}/runs/{run_id}`. The name is ignored when creating a transfer run.',
    )
    notificationPubsubTopic: Optional[str] = Field(
        None,
        description='Output only. Pub/Sub topic where a notification will be sent after this transfer run finishes. The format for specifying a pubsub topic is: `projects/{project}/topics/{topic}`',
    )
    params: Optional[Dict[str, Any]] = Field(
        None,
        description="Output only. Parameters specific to each data source. For more information see the bq tab in the 'Setting up a data transfer' section for each data source. For example the parameters for Cloud Storage transfers are listed here: https://cloud.google.com/bigquery-transfer/docs/cloud-storage-transfer#bq",
    )
    runTime: Optional[str] = Field(
        None,
        description='For batch transfer runs, specifies the date and time of the data should be ingested.',
    )
    schedule: Optional[str] = Field(
        None,
        description="Output only. Describes the schedule of this transfer run if it was created as part of a regular schedule. For batch transfer runs that are scheduled manually, this is empty. NOTE: the system might choose to delay the schedule depending on the current load, so `schedule_time` doesn't always match this.",
    )
    scheduleTime: Optional[str] = Field(
        None, description='Minimum time after which a transfer run can be started.'
    )
    startTime: Optional[str] = Field(
        None,
        description='Output only. Time when transfer run was started. Parameter ignored by server for input requests.',
    )
    state: Optional[State] = Field(
        None, description='Data transfer run state. Ignored for input requests.'
    )
    updateTime: Optional[str] = Field(
        None,
        description='Output only. Last time the data transfer run state was updated.',
    )
    userId: Optional[str] = Field(
        None,
        description='Deprecated. Unique ID of the user on whose behalf transfer is done.',
    )


class UserInfo(BaseModel):
    email: Optional[str] = Field(None, description='E-mail address of the user.')


class FieldXgafv(Enum):
    field_1 = '1'
    field_2 = '2'


class Alt(Enum):
    json = 'json'
    media = 'media'
    proto = 'proto'


class RunAttempt(Enum):
    RUN_ATTEMPT_UNSPECIFIED = 'RUN_ATTEMPT_UNSPECIFIED'
    LATEST = 'LATEST'


class States(RootModel[List[State]]):
    root: List[State]


class DataSourceIds(RootModel[List[str]]):
    root: List[str]


class MessageType(Enum):
    MESSAGE_SEVERITY_UNSPECIFIED = 'MESSAGE_SEVERITY_UNSPECIFIED'
    INFO = 'INFO'
    WARNING = 'WARNING'
    ERROR = 'ERROR'


class MessageTypes(RootModel[List[MessageType]]):
    root: List[MessageType]


class DataSource(BaseModel):
    authorizationType: Optional[AuthorizationType] = Field(
        None, description='Indicates the type of authorization.'
    )
    clientId: Optional[str] = Field(
        None,
        description='Data source client id which should be used to receive refresh token.',
    )
    dataRefreshType: Optional[DataRefreshType] = Field(
        None,
        description="Specifies whether the data source supports automatic data refresh for the past few days, and how it's supported. For some data sources, data might not be complete until a few days later, so it's useful to refresh data automatically.",
    )
    dataSourceId: Optional[str] = Field(None, description='Data source id.')
    defaultDataRefreshWindowDays: Optional[int] = Field(
        None,
        description='Default data refresh window on days. Only meaningful when `data_refresh_type` = `SLIDING_WINDOW`.',
    )
    defaultSchedule: Optional[str] = Field(
        None,
        description='Default data transfer schedule. Examples of valid schedules include: `1st,3rd monday of month 15:30`, `every wed,fri of jan,jun 13:15`, and `first sunday of quarter 00:00`.',
    )
    description: Optional[str] = Field(
        None, description='User friendly data source description string.'
    )
    displayName: Optional[str] = Field(
        None, description='User friendly data source name.'
    )
    helpUrl: Optional[str] = Field(
        None, description='Url for the help document for this data source.'
    )
    manualRunsDisabled: Optional[bool] = Field(
        None,
        description='Disables backfilling and manual run scheduling for the data source.',
    )
    minimumScheduleInterval: Optional[str] = Field(
        None, description='The minimum interval for scheduler to schedule runs.'
    )
    name: Optional[str] = Field(
        None, description='Output only. Data source resource name.'
    )
    parameters: Optional[List[DataSourceParameter]] = Field(
        None, description='Data source parameters.'
    )
    scopes: Optional[List[str]] = Field(
        None,
        description='Api auth scopes for which refresh token needs to be obtained. These are scopes needed by a data source to prepare data and ingest them into BigQuery, e.g., https://www.googleapis.com/auth/bigquery',
    )
    supportsCustomSchedule: Optional[bool] = Field(
        None,
        description='Specifies whether the data source supports a user defined schedule, or operates on the default schedule. When set to `true`, user can override default schedule.',
    )
    supportsMultipleTransfers: Optional[bool] = Field(
        None, description='Deprecated. This field has no effect.'
    )
    transferType: Optional[TransferType] = Field(
        None, description='Deprecated. This field has no effect.'
    )
    updateDeadlineSeconds: Optional[int] = Field(
        None,
        description='The number of seconds to wait for an update from the data source before the Data Transfer Service marks the transfer as FAILED.',
    )


class ListDataSourcesResponse(BaseModel):
    dataSources: Optional[List[DataSource]] = Field(
        None, description='List of supported data sources and their transfer settings.'
    )
    nextPageToken: Optional[str] = Field(
        None,
        description='Output only. The next-pagination token. For multiple-page list results, this token can be used as the `ListDataSourcesRequest.page_token` to request the next page of list results.',
    )


class ListLocationsResponse(BaseModel):
    locations: Optional[List[Location]] = Field(
        None,
        description='A list of locations that matches the specified filter in the request.',
    )
    nextPageToken: Optional[str] = Field(
        None, description='The standard List next-page token.'
    )


class ListTransferLogsResponse(BaseModel):
    nextPageToken: Optional[str] = Field(
        None,
        description='Output only. The next-pagination token. For multiple-page list results, this token can be used as the `GetTransferRunLogRequest.page_token` to request the next page of list results.',
    )
    transferMessages: Optional[List[TransferMessage]] = Field(
        None, description='Output only. The stored pipeline transfer messages.'
    )


class ListTransferRunsResponse(BaseModel):
    nextPageToken: Optional[str] = Field(
        None,
        description='Output only. The next-pagination token. For multiple-page list results, this token can be used as the `ListTransferRunsRequest.page_token` to request the next page of list results.',
    )
    transferRuns: Optional[List[TransferRun]] = Field(
        None, description='Output only. The stored pipeline transfer runs.'
    )


class ScheduleTransferRunsResponse(BaseModel):
    runs: Optional[List[TransferRun]] = Field(
        None, description='The transfer runs that were scheduled.'
    )


class StartManualTransferRunsRequest(BaseModel):
    requestedRunTime: Optional[str] = Field(
        None,
        description='Specific run_time for a transfer run to be started. The requested_run_time must not be in the future.',
    )
    requestedTimeRange: Optional[TimeRange] = Field(
        None, description='Time range for the transfer runs that should be started.'
    )


class StartManualTransferRunsResponse(BaseModel):
    runs: Optional[List[TransferRun]] = Field(
        None, description='The transfer runs that were created.'
    )


class TransferConfig(BaseModel):
    dataRefreshWindowDays: Optional[int] = Field(
        None,
        description='The number of days to look back to automatically refresh the data. For example, if `data_refresh_window_days = 10`, then every day BigQuery reingests data for [today-10, today-1], rather than ingesting data for just [today-1]. Only valid if the data source supports the feature. Set the value to 0 to use the default value.',
    )
    dataSourceId: Optional[str] = Field(
        None,
        description='Data source ID. This cannot be changed once data transfer is created. The full list of available data source IDs can be returned through an API call: https://cloud.google.com/bigquery-transfer/docs/reference/datatransfer/rest/v1/projects.locations.dataSources/list',
    )
    datasetRegion: Optional[str] = Field(
        None, description='Output only. Region in which BigQuery dataset is located.'
    )
    destinationDatasetId: Optional[str] = Field(
        None, description='The BigQuery target dataset id.'
    )
    disabled: Optional[bool] = Field(
        None,
        description='Is this config disabled. When set to true, no runs are scheduled for a given transfer.',
    )
    displayName: Optional[str] = Field(
        None, description='User specified display name for the data transfer.'
    )
    emailPreferences: Optional[EmailPreferences] = Field(
        None,
        description='Email notifications will be sent according to these preferences to the email address of the user who owns this transfer config.',
    )
    name: Optional[str] = Field(
        None,
        description='The resource name of the transfer config. Transfer config names have the form `projects/{project_id}/locations/{region}/transferConfigs/{config_id}`. Where `config_id` is usually a uuid, even though it is not guaranteed or required. The name is ignored when creating a transfer config.',
    )
    nextRunTime: Optional[str] = Field(
        None, description='Output only. Next time when data transfer will run.'
    )
    notificationPubsubTopic: Optional[str] = Field(
        None,
        description='Pub/Sub topic where notifications will be sent after transfer runs associated with this transfer config finish. The format for specifying a pubsub topic is: `projects/{project}/topics/{topic}`',
    )
    ownerInfo: Optional[UserInfo] = Field(
        None,
        description='Output only. Information about the user whose credentials are used to transfer data. Populated only for `transferConfigs.get` requests. In case the user information is not available, this field will not be populated.',
    )
    params: Optional[Dict[str, Any]] = Field(
        None,
        description="Parameters specific to each data source. For more information see the bq tab in the 'Setting up a data transfer' section for each data source. For example the parameters for Cloud Storage transfers are listed here: https://cloud.google.com/bigquery-transfer/docs/cloud-storage-transfer#bq",
    )
    schedule: Optional[str] = Field(
        None,
        description='Data transfer schedule. If the data source does not support a custom schedule, this should be empty. If it is empty, the default value for the data source will be used. The specified times are in UTC. Examples of valid format: `1st,3rd monday of month 15:30`, `every wed,fri of jan,jun 13:15`, and `first sunday of quarter 00:00`. See more explanation about the format here: https://cloud.google.com/appengine/docs/flexible/python/scheduling-jobs-with-cron-yaml#the_schedule_format NOTE: The minimum interval time between recurring transfers depends on the data source; refer to the documentation for your data source.',
    )
    scheduleOptions: Optional[ScheduleOptions] = Field(
        None, description='Options customizing the data transfer schedule.'
    )
    state: Optional[State] = Field(
        None,
        description='Output only. State of the most recently updated transfer run.',
    )
    updateTime: Optional[str] = Field(
        None,
        description='Output only. Data transfer modification time. Ignored by server on input.',
    )
    userId: Optional[str] = Field(
        None,
        description='Deprecated. Unique ID of the user on whose behalf transfer is done.',
    )


class ListTransferConfigsResponse(BaseModel):
    nextPageToken: Optional[str] = Field(
        None,
        description='Output only. The next-pagination token. For multiple-page list results, this token can be used as the `ListTransferConfigsRequest.page_token` to request the next page of list results.',
    )
    transferConfigs: Optional[List[TransferConfig]] = Field(
        None, description='Output only. The stored pipeline transfer configurations.'
    )


DataSourceParameter.model_rebuild()
